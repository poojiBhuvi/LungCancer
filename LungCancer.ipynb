{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfGK_3jIcQsz",
        "outputId": "2d0bde8d-82b0-4df9-a5a6-e2649d72c849"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ],
      "source": [
        "pip install kaggle\n",
        "! pip install -q kaggle\n",
        "import os\n",
        "if not os.path.isfile(os.path.expanduser('~/.kaggle/kaggle.json')):\n",
        "  from google.colab import files\n",
        "  print(\"Upload kaggle.json here\")\n",
        "  files.upload()\n",
        "\n",
        "if not os.path.isfile('IMDB Dataset.csv'):\n",
        "  !mkdir ~/.kaggle\n",
        "  !mv ./kaggle.json ~/.kaggle/\n",
        "  !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "  dataset_name = 'mohamedhanyyy/chest-ctscan-images'\n",
        "  zip_name = dataset_name.split('/')[-1]\n",
        "\n",
        "  !kaggle datasets download -d {dataset_name}\n",
        "  !unzip -q ./{zip_name}.zip -d .\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense,Conv2D, Flatten, MaxPool2D, Dropout\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential, load_model, Model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# File Directory for both the train and test\n",
        "train_path = \"C:\\Users\\Admin\\Downloads\\CODE\\CODE\\DATA\\Data\\train\"\n",
        "val_path = \"C:\\Users\\Admin\\Downloads\\CODE\\CODE\\DATA\\Data\\valid\"\n",
        "test_path = \"C:\\Users\\Admin\\Downloads\\CODE\\CODE\\DATA\\Data\\test\"\n",
        "# Define function to count number of images per class using a dictionary\n",
        "def GetDatasetSize(path):\n",
        "    num_of_image = {}\n",
        "    for folder in os.listdir(path):\n",
        "        # count files in the folder\n",
        "        num_of_image[folder] = len(os.listdir(os.path.join(path, folder)));\n",
        "    return num_of_image;\n",
        "\n",
        "# Get the number of images per class in each set (train, validation and test)\n",
        "train_set = GetDatasetSize(train_path)\n",
        "val_set = GetDatasetSize(val_path)\n",
        "test_set = GetDatasetSize(test_path)\n",
        "print(train_set,\"\\n\\n\",val_set,\"\\n\\n\",test_set)\n",
        "# Labels for each classs\n",
        "labels = ['squamous.cell.carcinoma', 'normal', 'adenocarcinoma', 'large.cell.carcinoma']\n",
        "\n",
        "# Create lists from previous dictionaries storing the count of images per category\n",
        "train_list = list(train_set.values())\n",
        "val_list = list(val_set.values())\n",
        "test_list = list(test_set.values())\n",
        "\n",
        "# Labels location and bars widht\n",
        "x = np.arange(len(labels))\n",
        "width = 0.25\n",
        "\n",
        "# Create plot and 3 sets of bars (train, val, test)\n",
        "fig, ax = plt.subplots()\n",
        "rects1 = ax.bar(x - width, train_list, width, label='Train')\n",
        "rects2 = ax.bar(x, val_list, width, label='Val')\n",
        "rects3 = ax.bar(x + width, test_list, width, label='Test')\n",
        "\n",
        "# Add labels, title, legend, count values...\n",
        "ax.set_ylabel('Images Count')\n",
        "ax.set_title('Dataset')\n",
        "ax.set_xticks(x, labels)\n",
        "plt.xticks(rotation=15)\n",
        "ax.legend()\n",
        "ax.bar_label(rects1)\n",
        "ax.bar_label(rects2)\n",
        "ax.bar_label(rects3)\n",
        "\n",
        "# Optimized layout and displaying plot\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "# Image data generator with specified augmentation configurations (mostly geometric transformations)\n",
        "train_datagen = ImageDataGenerator(rescale = 1.0/255.0,\n",
        "                                  horizontal_flip = True,\n",
        "                                  fill_mode = 'nearest',\n",
        "                                  zoom_range=0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  width_shift_range=0.2,\n",
        "                                  height_shift_range=0.2,\n",
        "                                  rotation_range=0.4)\n",
        "\n",
        "# Using data generator to create augmented data from image files in train_path directory\n",
        "train_data = train_datagen.flow_from_directory(train_path,\n",
        "                                                   batch_size = 5,\n",
        "                                                   target_size = (350,350),\n",
        "                                                   class_mode = 'categorical')\n",
        "\n",
        "# Dicctionary with class names to their respective indices in the generated data\n",
        "train_data.class_indices\n",
        "val_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "val_data = val_datagen.flow_from_directory(val_path,\n",
        "                                                   batch_size = 5,\n",
        "                                                   target_size = (350,350),\n",
        "                                                   class_mode = 'categorical')\n",
        "val_data.class_indices\n",
        "{'adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib': 0,\n",
        " 'large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa': 1,\n",
        " 'normal': 2,\n",
        " 'squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa': 3}\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "test_data = test_datagen.flow_from_directory(test_path,\n",
        "                                                   batch_size = 5,\n",
        "                                                   target_size = (350,350),\n",
        "                                                   class_mode = 'categorical')\n",
        "test_data.class_indices\n",
        "{'adenocarcinoma': 0,\n",
        " 'large.cell.carcinoma': 1,\n",
        " 'normal': 2,\n",
        " 'squamous.cell.carcinoma': 3}\n",
        "# Function to plot sample images with labels\n",
        "def plot_sample_images(images, labels, class_indices):\n",
        "    class_labels = list(class_indices.keys())\n",
        "    fig, axs = plt.subplots(1, len(images), figsize=(15, 5))\n",
        "    fig.subplots_adjust(wspace=0.5)  # Adjust the width space between subplots\n",
        "\n",
        "    for i in range(len(images)):\n",
        "        axs[i].imshow(images[i])\n",
        "        axs[i].set_title(\"Label: {}\".format(class_labels[np.argmax(labels[i])]), fontsize=10)  # Adjust fontsize as needed\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Sample and plotting of 3 images with their respective labels from train_data\n",
        "sample_images, sample_labels = next(train_data)\n",
        "plot_sample_images(sample_images[:3], sample_labels[:3], train_data.class_indices)\n",
        "base_model = EfficientNetB0(input_shape = (350, 350, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet')\n",
        "mc = ModelCheckpoint(\n",
        "    filepath=\"./ct_effnet_best_model.hdf5\",\n",
        "    monitor= 'val_accuracy',\n",
        "    verbose= 1,\n",
        "    save_best_only= True,\n",
        "    mode = 'auto'\n",
        "    );\n",
        "\n",
        "call_back = [ mc];\n",
        "\n",
        "tensorboard = TensorBoard(log_dir = 'logs')\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
        "                              mode='auto',verbose=1)\n",
        "\n",
        "#We also add a earlystop for prevent the computer from wasting time if it's not making progress.\n",
        "\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True)\n",
        "#Customize our base model\n",
        "EffNetmodel = base_model.output\n",
        "EffNetmodel = tf.keras.layers.GlobalAveragePooling2D()(EffNetmodel)\n",
        "# to provide overfitting problem\n",
        "EffNetmodel = tf.keras.layers.Dropout(rate=0.5)(EffNetmodel)\n",
        "\n",
        "#Finally, we add a layer with 4 'neurons' that will help us classify things into different categories.\n",
        "EffNetmodel = tf.keras.layers.Dense(4,activation='softmax')(EffNetmodel)\n",
        "#We put together the original EfficientNetB0 and our new custom parts\n",
        "EffNetmodel = tf.keras.models.Model(inputs=base_model.input, outputs = EffNetmodel)\n",
        "\n",
        "#Compile up the rules and tools for training your neural network.\n",
        "#The optimizer determines how the model should update its internal parameters, the loss function quantifies how well the model is doing, and the metrics provide additional measures to track the model's performance.\n",
        "EffNetmodel.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])\n",
        "%time\n",
        "EffNetB0 = EffNetmodel.fit(\n",
        "    train_data,\n",
        "    steps_per_epoch = train_data.samples//train_data.batch_size,\n",
        "    epochs = 15,\n",
        "    validation_data = val_data,\n",
        "    validation_steps = val_data.samples//val_data.batch_size,\n",
        "    callbacks = [tensorboard, mc, reduce_lr, early_stopping]\n",
        "    )\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "\n",
        "# Assuming you have trained and named your model 'model'\n",
        "# model = your_model_training_function()\n",
        "\n",
        "# Save the model\n",
        "EffNetB0.save(\"lungcancer11.h5\")\n",
        "\n",
        "# Optionally, if you want to load the model later:\n",
        "# loaded_model = load_model(\"lungcancer.h5\")\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "saved_model_path = \"/content/ct_effnet_best_model.hdf5\"\n",
        "model = load_model(saved_model_path)\n",
        "\n",
        "# Load and preprocess the new image data using the same data generator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load and preprocess the new image data\n",
        "img_path = '/content/Data/test/adenocarcinoma/000113 (7).png'  # Update with the path to your new image\n",
        "img = image.load_img(img_path, target_size=(350, 350))  # Assuming your model expects input size of 350x350\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = img_array.reshape((1,) + img_array.shape)  # Reshape to (1, height, width, channels)\n",
        "\n",
        "# Preprocess the image using the same data generator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255.0,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest',\n",
        "                                   zoom_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   rotation_range=0.4)\n",
        "\n",
        "# No need for augmentation, as we're dealing with a single image\n",
        "img_generator = train_datagen.flow(img_array, batch_size=1)\n",
        "\n",
        "# Now you can use the model to make predictions\n",
        "predictions = model.predict(img_generator)\n",
        "\n",
        "# Print the predictions\n",
        "print(predictions)\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the saved model\n",
        "saved_model_path = \"/content/ct_effnet_best_model.hdf5\"\n",
        "model = load_model(saved_model_path)\n",
        "\n",
        "# Load and preprocess the new image data\n",
        "img_path = '/content/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib/000009 (3).png'  # Update with the path to your new image\n",
        "img = image.load_img(img_path, target_size=(350, 350))  # Assuming your model expects input size of 350x350\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Rescale to [0, 1] range (assuming you rescaled images in the ImageDataGenerator)\n",
        "\n",
        "# Now you can use the model to make predictions\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the class indices\n",
        "class_indices = train_data.class_indices\n",
        "\n",
        "# Invert the dictionary to map indices to class names\n",
        "inverse_class_indices = dict((v, k) for k, v in class_indices.items())\n",
        "\n",
        "# Get the predicted class index\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Get the predicted class name\n",
        "predicted_class_name = inverse_class_indices[predicted_class_index]\n",
        "\n",
        "# Print the predicted class name\n",
        "print(\"Predicted class:\", predicted_class_name)\n",
        "\n",
        "pip install pillow\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from google.colab import files\n",
        "\n",
        "# Load and preprocess the image\n",
        "def load_and_preprocess_image():\n",
        "    # Prompt the user to upload a file\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Get the path of the uploaded file\n",
        "    for filename in uploaded.keys():\n",
        "        image_path = filename\n",
        "\n",
        "    # Load and preprocess the new image\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize((350, 350))  # Adjust the target size to match your model's input size\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize pixel values to the range [0, 1]\n",
        "\n",
        "    return img_array\n",
        "\n",
        "# Load your own model\n",
        "model = load_model(\"/content/ct_effnet_best_model.hdf5\")  # Replace \"your_model.h5\" with the path to your model file\n",
        "\n",
        "# Example usage:\n",
        "new_image = load_and_preprocess_image()\n",
        "\n",
        "# Assuming your model is loaded and named 'model'\n",
        "predictions = model.predict(new_image)\n",
        "\n",
        "# Process the predictions as needed for your application\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "print(\"Predicted Class Index:\", predicted_class_index)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
